{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Nombre:** Miller Alexis Quintero García"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EJERCICIO 1 - BASICO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El fichero `datos_pago_microcreditos.csv` contiene 30000 transacciones bancarias relativas al pago o impago de microcréditos. El dataset consta de 62 dimensiones propietarias de las cuales el banco no ha proporcionado información por confidencialidad, a parte de su valor. La matriz de entrada se encuentra en `x_train`, e `y_train` contiene la etiqueta relativa a esa transacción, un 1 indica que si se pago el microcredito y un 0 que no se pago."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considera que el tamaño del dataset es lo suficientemente grande como para que dependiendo de los recursos de la máquina, pueda tardar varios minutos en entrenar modelos complejos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecuta el código inicial para estandarizar los datos y contesta las preguntas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_file='datos_pago_microcreditos.csv'\n",
    "\n",
    "pdl=pd.read_csv(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>payment</th>\n",
       "      <th>var1</th>\n",
       "      <th>var2</th>\n",
       "      <th>var3</th>\n",
       "      <th>var4</th>\n",
       "      <th>var5</th>\n",
       "      <th>var6</th>\n",
       "      <th>var7</th>\n",
       "      <th>var8</th>\n",
       "      <th>var9</th>\n",
       "      <th>...</th>\n",
       "      <th>var21</th>\n",
       "      <th>var22</th>\n",
       "      <th>var23</th>\n",
       "      <th>var24</th>\n",
       "      <th>var25</th>\n",
       "      <th>var26</th>\n",
       "      <th>var27</th>\n",
       "      <th>var28</th>\n",
       "      <th>var29</th>\n",
       "      <th>var30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Success</td>\n",
       "      <td>qw</td>\n",
       "      <td>hk</td>\n",
       "      <td>3.11</td>\n",
       "      <td>16.06</td>\n",
       "      <td>-4.60</td>\n",
       "      <td>22.34</td>\n",
       "      <td>13.53</td>\n",
       "      <td>1.53</td>\n",
       "      <td>nv</td>\n",
       "      <td>...</td>\n",
       "      <td>8.94</td>\n",
       "      <td>-12.76</td>\n",
       "      <td>ub</td>\n",
       "      <td>12.06</td>\n",
       "      <td>2.46</td>\n",
       "      <td>4.73</td>\n",
       "      <td>-1.72</td>\n",
       "      <td>0.91</td>\n",
       "      <td>ev</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Denied</td>\n",
       "      <td>qw</td>\n",
       "      <td>rv</td>\n",
       "      <td>3.35</td>\n",
       "      <td>11.18</td>\n",
       "      <td>-18.55</td>\n",
       "      <td>6.68</td>\n",
       "      <td>12.78</td>\n",
       "      <td>6.62</td>\n",
       "      <td>nv</td>\n",
       "      <td>...</td>\n",
       "      <td>31.02</td>\n",
       "      <td>34.76</td>\n",
       "      <td>cz</td>\n",
       "      <td>1.44</td>\n",
       "      <td>9.44</td>\n",
       "      <td>13.56</td>\n",
       "      <td>-2.24</td>\n",
       "      <td>0.24</td>\n",
       "      <td>ev</td>\n",
       "      <td>-2.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Denied</td>\n",
       "      <td>qw</td>\n",
       "      <td>zg</td>\n",
       "      <td>4.15</td>\n",
       "      <td>29.19</td>\n",
       "      <td>18.91</td>\n",
       "      <td>16.40</td>\n",
       "      <td>3.67</td>\n",
       "      <td>5.72</td>\n",
       "      <td>ch</td>\n",
       "      <td>...</td>\n",
       "      <td>23.26</td>\n",
       "      <td>9.50</td>\n",
       "      <td>ri</td>\n",
       "      <td>7.77</td>\n",
       "      <td>8.70</td>\n",
       "      <td>-1.75</td>\n",
       "      <td>5.96</td>\n",
       "      <td>1.91</td>\n",
       "      <td>ev</td>\n",
       "      <td>22.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Success</td>\n",
       "      <td>wv</td>\n",
       "      <td>js</td>\n",
       "      <td>6.23</td>\n",
       "      <td>15.70</td>\n",
       "      <td>2.81</td>\n",
       "      <td>4.46</td>\n",
       "      <td>5.13</td>\n",
       "      <td>8.66</td>\n",
       "      <td>ja</td>\n",
       "      <td>...</td>\n",
       "      <td>29.25</td>\n",
       "      <td>-1.53</td>\n",
       "      <td>ri</td>\n",
       "      <td>8.94</td>\n",
       "      <td>19.33</td>\n",
       "      <td>23.73</td>\n",
       "      <td>5.54</td>\n",
       "      <td>0.85</td>\n",
       "      <td>ev</td>\n",
       "      <td>36.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Success</td>\n",
       "      <td>ma</td>\n",
       "      <td>xn</td>\n",
       "      <td>1.28</td>\n",
       "      <td>20.71</td>\n",
       "      <td>14.98</td>\n",
       "      <td>11.19</td>\n",
       "      <td>17.66</td>\n",
       "      <td>1.13</td>\n",
       "      <td>nv</td>\n",
       "      <td>...</td>\n",
       "      <td>2.19</td>\n",
       "      <td>10.24</td>\n",
       "      <td>ub</td>\n",
       "      <td>8.92</td>\n",
       "      <td>5.48</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>4.01</td>\n",
       "      <td>1.21</td>\n",
       "      <td>ev</td>\n",
       "      <td>11.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>Success</td>\n",
       "      <td>qw</td>\n",
       "      <td>zg</td>\n",
       "      <td>3.85</td>\n",
       "      <td>12.75</td>\n",
       "      <td>47.62</td>\n",
       "      <td>3.34</td>\n",
       "      <td>17.22</td>\n",
       "      <td>7.00</td>\n",
       "      <td>ch</td>\n",
       "      <td>...</td>\n",
       "      <td>25.00</td>\n",
       "      <td>18.14</td>\n",
       "      <td>tf</td>\n",
       "      <td>8.54</td>\n",
       "      <td>14.95</td>\n",
       "      <td>32.69</td>\n",
       "      <td>-3.71</td>\n",
       "      <td>1.20</td>\n",
       "      <td>ev</td>\n",
       "      <td>-7.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>Denied</td>\n",
       "      <td>kq</td>\n",
       "      <td>bq</td>\n",
       "      <td>3.32</td>\n",
       "      <td>25.31</td>\n",
       "      <td>15.90</td>\n",
       "      <td>10.96</td>\n",
       "      <td>10.13</td>\n",
       "      <td>10.32</td>\n",
       "      <td>ch</td>\n",
       "      <td>...</td>\n",
       "      <td>26.49</td>\n",
       "      <td>22.88</td>\n",
       "      <td>qu</td>\n",
       "      <td>12.11</td>\n",
       "      <td>11.45</td>\n",
       "      <td>11.56</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.92</td>\n",
       "      <td>ev</td>\n",
       "      <td>13.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>Denied</td>\n",
       "      <td>kq</td>\n",
       "      <td>js</td>\n",
       "      <td>2.98</td>\n",
       "      <td>19.28</td>\n",
       "      <td>16.20</td>\n",
       "      <td>-1.70</td>\n",
       "      <td>9.45</td>\n",
       "      <td>-8.44</td>\n",
       "      <td>ch</td>\n",
       "      <td>...</td>\n",
       "      <td>39.61</td>\n",
       "      <td>4.40</td>\n",
       "      <td>ub</td>\n",
       "      <td>7.75</td>\n",
       "      <td>1.65</td>\n",
       "      <td>17.83</td>\n",
       "      <td>9.67</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>ev</td>\n",
       "      <td>31.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>Success</td>\n",
       "      <td>qw</td>\n",
       "      <td>py</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>16.41</td>\n",
       "      <td>22.80</td>\n",
       "      <td>-9.99</td>\n",
       "      <td>26.89</td>\n",
       "      <td>-1.10</td>\n",
       "      <td>ch</td>\n",
       "      <td>...</td>\n",
       "      <td>44.22</td>\n",
       "      <td>0.46</td>\n",
       "      <td>tf</td>\n",
       "      <td>11.50</td>\n",
       "      <td>5.90</td>\n",
       "      <td>20.33</td>\n",
       "      <td>4.17</td>\n",
       "      <td>0.78</td>\n",
       "      <td>ev</td>\n",
       "      <td>40.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>Success</td>\n",
       "      <td>qw</td>\n",
       "      <td>js</td>\n",
       "      <td>6.03</td>\n",
       "      <td>-6.99</td>\n",
       "      <td>-28.71</td>\n",
       "      <td>11.82</td>\n",
       "      <td>4.71</td>\n",
       "      <td>5.00</td>\n",
       "      <td>ch</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>25.11</td>\n",
       "      <td>yv</td>\n",
       "      <td>7.67</td>\n",
       "      <td>6.34</td>\n",
       "      <td>20.05</td>\n",
       "      <td>7.85</td>\n",
       "      <td>1.20</td>\n",
       "      <td>ev</td>\n",
       "      <td>4.74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       payment var1 var2  var3   var4   var5   var6   var7   var8 var9  ...  \\\n",
       "0      Success   qw   hk  3.11  16.06  -4.60  22.34  13.53   1.53   nv  ...   \n",
       "1       Denied   qw   rv  3.35  11.18 -18.55   6.68  12.78   6.62   nv  ...   \n",
       "2       Denied   qw   zg  4.15  29.19  18.91  16.40   3.67   5.72   ch  ...   \n",
       "3      Success   wv   js  6.23  15.70   2.81   4.46   5.13   8.66   ja  ...   \n",
       "4      Success   ma   xn  1.28  20.71  14.98  11.19  17.66   1.13   nv  ...   \n",
       "...        ...  ...  ...   ...    ...    ...    ...    ...    ...  ...  ...   \n",
       "29995  Success   qw   zg  3.85  12.75  47.62   3.34  17.22   7.00   ch  ...   \n",
       "29996   Denied   kq   bq  3.32  25.31  15.90  10.96  10.13  10.32   ch  ...   \n",
       "29997   Denied   kq   js  2.98  19.28  16.20  -1.70   9.45  -8.44   ch  ...   \n",
       "29998  Success   qw   py -0.30  16.41  22.80  -9.99  26.89  -1.10   ch  ...   \n",
       "29999  Success   qw   js  6.03  -6.99 -28.71  11.82   4.71   5.00   ch  ...   \n",
       "\n",
       "       var21  var22  var23  var24  var25  var26  var27 var28  var29  var30  \n",
       "0       8.94 -12.76     ub  12.06   2.46   4.73  -1.72  0.91     ev   8.00  \n",
       "1      31.02  34.76     cz   1.44   9.44  13.56  -2.24  0.24     ev  -2.90  \n",
       "2      23.26   9.50     ri   7.77   8.70  -1.75   5.96  1.91     ev  22.67  \n",
       "3      29.25  -1.53     ri   8.94  19.33  23.73   5.54  0.85     ev  36.31  \n",
       "4       2.19  10.24     ub   8.92   5.48  -0.28   4.01  1.21     ev  11.33  \n",
       "...      ...    ...    ...    ...    ...    ...    ...   ...    ...    ...  \n",
       "29995  25.00  18.14     tf   8.54  14.95  32.69  -3.71  1.20     ev  -7.12  \n",
       "29996  26.49  22.88     qu  12.11  11.45  11.56   3.52  0.92     ev  13.28  \n",
       "29997  39.61   4.40     ub   7.75   1.65  17.83   9.67 -0.64     ev  31.07  \n",
       "29998  44.22   0.46     tf  11.50   5.90  20.33   4.17  0.78     ev  40.53  \n",
       "29999  -0.06  25.11     yv   7.67   6.34  20.05   7.85  1.20     ev   4.74  \n",
       "\n",
       "[30000 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   payment var1 var2  var3   var4   var5   var6   var7  var8 var9  ...  var21  \\\n",
      "0  Success   qw   hk  3.11  16.06  -4.60  22.34  13.53  1.53   nv  ...   8.94   \n",
      "1   Denied   qw   rv  3.35  11.18 -18.55   6.68  12.78  6.62   nv  ...  31.02   \n",
      "2   Denied   qw   zg  4.15  29.19  18.91  16.40   3.67  5.72   ch  ...  23.26   \n",
      "3  Success   wv   js  6.23  15.70   2.81   4.46   5.13  8.66   ja  ...  29.25   \n",
      "4  Success   ma   xn  1.28  20.71  14.98  11.19  17.66  1.13   nv  ...   2.19   \n",
      "\n",
      "   var22  var23  var24  var25  var26  var27 var28  var29  var30  \n",
      "0 -12.76     ub  12.06   2.46   4.73  -1.72  0.91     ev   8.00  \n",
      "1  34.76     cz   1.44   9.44  13.56  -2.24  0.24     ev  -2.90  \n",
      "2   9.50     ri   7.77   8.70  -1.75   5.96  1.91     ev  22.67  \n",
      "3  -1.53     ri   8.94  19.33  23.73   5.54  0.85     ev  36.31  \n",
      "4  10.24     ub   8.92   5.48  -0.28   4.01  1.21     ev  11.33  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "print(pdl.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "payment    0\n",
      "var1       0\n",
      "var2       0\n",
      "var3       0\n",
      "var4       0\n",
      "var5       0\n",
      "var6       0\n",
      "var7       0\n",
      "var8       0\n",
      "var9       0\n",
      "var10      0\n",
      "var11      0\n",
      "var12      0\n",
      "var13      0\n",
      "var14      0\n",
      "var15      0\n",
      "var16      0\n",
      "var17      0\n",
      "var18      0\n",
      "var19      0\n",
      "var20      0\n",
      "var21      0\n",
      "var22      0\n",
      "var23      0\n",
      "var24      0\n",
      "var25      0\n",
      "var26      0\n",
      "var27      0\n",
      "var28      0\n",
      "var29      0\n",
      "var30      0\n",
      "dtype: int64\n",
      "payment    0\n",
      "var1       0\n",
      "var2       0\n",
      "var3       0\n",
      "var4       0\n",
      "var5       0\n",
      "var6       0\n",
      "var7       0\n",
      "var8       0\n",
      "var9       0\n",
      "var10      0\n",
      "var11      0\n",
      "var12      0\n",
      "var13      0\n",
      "var14      0\n",
      "var15      0\n",
      "var16      0\n",
      "var17      0\n",
      "var18      0\n",
      "var19      0\n",
      "var20      0\n",
      "var21      0\n",
      "var22      0\n",
      "var23      0\n",
      "var24      0\n",
      "var25      0\n",
      "var26      0\n",
      "var27      0\n",
      "var28      0\n",
      "var29      0\n",
      "var30      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Vemos si hay valores nulos\n",
    "print(pdl.isnull().sum())\n",
    "# Vemos si hay valores NaN\n",
    "print(pdl.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30000 entries, 0 to 29999\n",
      "Data columns (total 31 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   payment  30000 non-null  object \n",
      " 1   var1     30000 non-null  object \n",
      " 2   var2     30000 non-null  object \n",
      " 3   var3     30000 non-null  float64\n",
      " 4   var4     30000 non-null  float64\n",
      " 5   var5     30000 non-null  float64\n",
      " 6   var6     30000 non-null  float64\n",
      " 7   var7     30000 non-null  float64\n",
      " 8   var8     30000 non-null  float64\n",
      " 9   var9     30000 non-null  object \n",
      " 10  var10    30000 non-null  object \n",
      " 11  var11    30000 non-null  object \n",
      " 12  var12    30000 non-null  float64\n",
      " 13  var13    30000 non-null  object \n",
      " 14  var14    30000 non-null  float64\n",
      " 15  var15    30000 non-null  float64\n",
      " 16  var16    30000 non-null  float64\n",
      " 17  var17    30000 non-null  object \n",
      " 18  var18    30000 non-null  float64\n",
      " 19  var19    30000 non-null  object \n",
      " 20  var20    30000 non-null  float64\n",
      " 21  var21    30000 non-null  float64\n",
      " 22  var22    30000 non-null  float64\n",
      " 23  var23    30000 non-null  object \n",
      " 24  var24    30000 non-null  float64\n",
      " 25  var25    30000 non-null  float64\n",
      " 26  var26    30000 non-null  float64\n",
      " 27  var27    30000 non-null  float64\n",
      " 28  var28    30000 non-null  float64\n",
      " 29  var29    30000 non-null  object \n",
      " 30  var30    30000 non-null  float64\n",
      "dtypes: float64(20), object(11)\n",
      "memory usage: 7.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(pdl.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               var3          var4          var5          var6          var7  \\\n",
      "count  30000.000000  30000.000000  30000.000000  30000.000000  30000.000000   \n",
      "mean       3.018848     13.941943     19.981561      8.009453      9.110358   \n",
      "std        3.004458     14.028019     19.866781      8.013395      8.976009   \n",
      "min       -8.190000    -43.660000    -55.100000    -23.630000    -27.580000   \n",
      "25%        0.990000      4.450000      6.520000      2.550000      3.050000   \n",
      "50%        3.040000     13.920000     19.980000      8.010000      9.170000   \n",
      "75%        5.040000     23.520000     33.452500     13.430000     15.152500   \n",
      "max       15.160000     76.780000    107.080000     44.330000     48.390000   \n",
      "\n",
      "               var8         var12         var14         var15         var16  \\\n",
      "count  30000.000000  30000.000000  30000.000000  30000.000000  30000.000000   \n",
      "mean       5.993785      7.020662      2.007760     17.118747     10.919426   \n",
      "std        6.035204      7.004504      2.001967     16.900037     10.977430   \n",
      "min      -17.940000    -29.340000     -5.500000    -54.270000    -34.510000   \n",
      "25%        1.910000      2.320000      0.650000      5.677500      3.470000   \n",
      "50%        5.960000      7.020000      2.000000     17.120000     10.900000   \n",
      "75%       10.050000     11.760000      3.370000     28.620000     18.310000   \n",
      "max       29.100000     37.370000     10.090000     81.410000     60.720000   \n",
      "\n",
      "              var18         var20         var21         var22         var24  \\\n",
      "count  30000.000000  30000.000000  30000.000000  30000.000000  30000.000000   \n",
      "mean      19.040852     18.018673     15.092997     12.958633      5.003848   \n",
      "std       18.938509     17.990146     15.040573     12.969523      5.017593   \n",
      "min      -52.450000    -51.930000    -54.070000    -37.780000    -15.890000   \n",
      "25%        6.420000      6.027500      4.887500      4.190000      1.630000   \n",
      "50%       19.200000     18.015000     15.200000     12.910000      5.020000   \n",
      "75%       31.700000     30.142500     25.220000     21.630000      8.400000   \n",
      "max      101.920000     97.280000     77.410000     75.450000     24.290000   \n",
      "\n",
      "              var25         var26         var27        var28         var30  \n",
      "count  30000.000000  30000.000000  30000.000000  30000.00000  30000.000000  \n",
      "mean       9.969102     12.081941      4.015074      1.00956     16.040880  \n",
      "std        9.997636     12.013399      4.010969      1.00323     16.038787  \n",
      "min      -29.580000    -46.500000    -14.170000     -3.45000    -49.930000  \n",
      "25%        3.240000      3.890000      1.310000      0.33000      5.360000  \n",
      "50%        9.930000     12.110000      3.990000      1.01000     16.140000  \n",
      "75%       16.680000     20.160000      6.710000      1.68000     26.780000  \n",
      "max       52.930000     58.830000     20.350000      5.07000     82.050000  \n"
     ]
    }
   ],
   "source": [
    "print(pdl.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>payment</th>\n",
       "      <th>var1</th>\n",
       "      <th>var2</th>\n",
       "      <th>var3</th>\n",
       "      <th>var4</th>\n",
       "      <th>var5</th>\n",
       "      <th>var6</th>\n",
       "      <th>var7</th>\n",
       "      <th>var8</th>\n",
       "      <th>var9</th>\n",
       "      <th>...</th>\n",
       "      <th>var21</th>\n",
       "      <th>var22</th>\n",
       "      <th>var23</th>\n",
       "      <th>var24</th>\n",
       "      <th>var25</th>\n",
       "      <th>var26</th>\n",
       "      <th>var27</th>\n",
       "      <th>var28</th>\n",
       "      <th>var29</th>\n",
       "      <th>var30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>qw</td>\n",
       "      <td>hk</td>\n",
       "      <td>3.11</td>\n",
       "      <td>16.06</td>\n",
       "      <td>-4.60</td>\n",
       "      <td>22.34</td>\n",
       "      <td>13.53</td>\n",
       "      <td>1.53</td>\n",
       "      <td>nv</td>\n",
       "      <td>...</td>\n",
       "      <td>8.94</td>\n",
       "      <td>-12.76</td>\n",
       "      <td>ub</td>\n",
       "      <td>12.06</td>\n",
       "      <td>2.46</td>\n",
       "      <td>4.73</td>\n",
       "      <td>-1.72</td>\n",
       "      <td>0.91</td>\n",
       "      <td>ev</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>qw</td>\n",
       "      <td>rv</td>\n",
       "      <td>3.35</td>\n",
       "      <td>11.18</td>\n",
       "      <td>-18.55</td>\n",
       "      <td>6.68</td>\n",
       "      <td>12.78</td>\n",
       "      <td>6.62</td>\n",
       "      <td>nv</td>\n",
       "      <td>...</td>\n",
       "      <td>31.02</td>\n",
       "      <td>34.76</td>\n",
       "      <td>cz</td>\n",
       "      <td>1.44</td>\n",
       "      <td>9.44</td>\n",
       "      <td>13.56</td>\n",
       "      <td>-2.24</td>\n",
       "      <td>0.24</td>\n",
       "      <td>ev</td>\n",
       "      <td>-2.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>qw</td>\n",
       "      <td>zg</td>\n",
       "      <td>4.15</td>\n",
       "      <td>29.19</td>\n",
       "      <td>18.91</td>\n",
       "      <td>16.40</td>\n",
       "      <td>3.67</td>\n",
       "      <td>5.72</td>\n",
       "      <td>ch</td>\n",
       "      <td>...</td>\n",
       "      <td>23.26</td>\n",
       "      <td>9.50</td>\n",
       "      <td>ri</td>\n",
       "      <td>7.77</td>\n",
       "      <td>8.70</td>\n",
       "      <td>-1.75</td>\n",
       "      <td>5.96</td>\n",
       "      <td>1.91</td>\n",
       "      <td>ev</td>\n",
       "      <td>22.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>wv</td>\n",
       "      <td>js</td>\n",
       "      <td>6.23</td>\n",
       "      <td>15.70</td>\n",
       "      <td>2.81</td>\n",
       "      <td>4.46</td>\n",
       "      <td>5.13</td>\n",
       "      <td>8.66</td>\n",
       "      <td>ja</td>\n",
       "      <td>...</td>\n",
       "      <td>29.25</td>\n",
       "      <td>-1.53</td>\n",
       "      <td>ri</td>\n",
       "      <td>8.94</td>\n",
       "      <td>19.33</td>\n",
       "      <td>23.73</td>\n",
       "      <td>5.54</td>\n",
       "      <td>0.85</td>\n",
       "      <td>ev</td>\n",
       "      <td>36.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>ma</td>\n",
       "      <td>xn</td>\n",
       "      <td>1.28</td>\n",
       "      <td>20.71</td>\n",
       "      <td>14.98</td>\n",
       "      <td>11.19</td>\n",
       "      <td>17.66</td>\n",
       "      <td>1.13</td>\n",
       "      <td>nv</td>\n",
       "      <td>...</td>\n",
       "      <td>2.19</td>\n",
       "      <td>10.24</td>\n",
       "      <td>ub</td>\n",
       "      <td>8.92</td>\n",
       "      <td>5.48</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>4.01</td>\n",
       "      <td>1.21</td>\n",
       "      <td>ev</td>\n",
       "      <td>11.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>1</td>\n",
       "      <td>qw</td>\n",
       "      <td>zg</td>\n",
       "      <td>3.85</td>\n",
       "      <td>12.75</td>\n",
       "      <td>47.62</td>\n",
       "      <td>3.34</td>\n",
       "      <td>17.22</td>\n",
       "      <td>7.00</td>\n",
       "      <td>ch</td>\n",
       "      <td>...</td>\n",
       "      <td>25.00</td>\n",
       "      <td>18.14</td>\n",
       "      <td>tf</td>\n",
       "      <td>8.54</td>\n",
       "      <td>14.95</td>\n",
       "      <td>32.69</td>\n",
       "      <td>-3.71</td>\n",
       "      <td>1.20</td>\n",
       "      <td>ev</td>\n",
       "      <td>-7.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>0</td>\n",
       "      <td>kq</td>\n",
       "      <td>bq</td>\n",
       "      <td>3.32</td>\n",
       "      <td>25.31</td>\n",
       "      <td>15.90</td>\n",
       "      <td>10.96</td>\n",
       "      <td>10.13</td>\n",
       "      <td>10.32</td>\n",
       "      <td>ch</td>\n",
       "      <td>...</td>\n",
       "      <td>26.49</td>\n",
       "      <td>22.88</td>\n",
       "      <td>qu</td>\n",
       "      <td>12.11</td>\n",
       "      <td>11.45</td>\n",
       "      <td>11.56</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.92</td>\n",
       "      <td>ev</td>\n",
       "      <td>13.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>0</td>\n",
       "      <td>kq</td>\n",
       "      <td>js</td>\n",
       "      <td>2.98</td>\n",
       "      <td>19.28</td>\n",
       "      <td>16.20</td>\n",
       "      <td>-1.70</td>\n",
       "      <td>9.45</td>\n",
       "      <td>-8.44</td>\n",
       "      <td>ch</td>\n",
       "      <td>...</td>\n",
       "      <td>39.61</td>\n",
       "      <td>4.40</td>\n",
       "      <td>ub</td>\n",
       "      <td>7.75</td>\n",
       "      <td>1.65</td>\n",
       "      <td>17.83</td>\n",
       "      <td>9.67</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>ev</td>\n",
       "      <td>31.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>1</td>\n",
       "      <td>qw</td>\n",
       "      <td>py</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>16.41</td>\n",
       "      <td>22.80</td>\n",
       "      <td>-9.99</td>\n",
       "      <td>26.89</td>\n",
       "      <td>-1.10</td>\n",
       "      <td>ch</td>\n",
       "      <td>...</td>\n",
       "      <td>44.22</td>\n",
       "      <td>0.46</td>\n",
       "      <td>tf</td>\n",
       "      <td>11.50</td>\n",
       "      <td>5.90</td>\n",
       "      <td>20.33</td>\n",
       "      <td>4.17</td>\n",
       "      <td>0.78</td>\n",
       "      <td>ev</td>\n",
       "      <td>40.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>1</td>\n",
       "      <td>qw</td>\n",
       "      <td>js</td>\n",
       "      <td>6.03</td>\n",
       "      <td>-6.99</td>\n",
       "      <td>-28.71</td>\n",
       "      <td>11.82</td>\n",
       "      <td>4.71</td>\n",
       "      <td>5.00</td>\n",
       "      <td>ch</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>25.11</td>\n",
       "      <td>yv</td>\n",
       "      <td>7.67</td>\n",
       "      <td>6.34</td>\n",
       "      <td>20.05</td>\n",
       "      <td>7.85</td>\n",
       "      <td>1.20</td>\n",
       "      <td>ev</td>\n",
       "      <td>4.74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       payment var1 var2  var3   var4   var5   var6   var7   var8 var9  ...  \\\n",
       "0            1   qw   hk  3.11  16.06  -4.60  22.34  13.53   1.53   nv  ...   \n",
       "1            0   qw   rv  3.35  11.18 -18.55   6.68  12.78   6.62   nv  ...   \n",
       "2            0   qw   zg  4.15  29.19  18.91  16.40   3.67   5.72   ch  ...   \n",
       "3            1   wv   js  6.23  15.70   2.81   4.46   5.13   8.66   ja  ...   \n",
       "4            1   ma   xn  1.28  20.71  14.98  11.19  17.66   1.13   nv  ...   \n",
       "...        ...  ...  ...   ...    ...    ...    ...    ...    ...  ...  ...   \n",
       "29995        1   qw   zg  3.85  12.75  47.62   3.34  17.22   7.00   ch  ...   \n",
       "29996        0   kq   bq  3.32  25.31  15.90  10.96  10.13  10.32   ch  ...   \n",
       "29997        0   kq   js  2.98  19.28  16.20  -1.70   9.45  -8.44   ch  ...   \n",
       "29998        1   qw   py -0.30  16.41  22.80  -9.99  26.89  -1.10   ch  ...   \n",
       "29999        1   qw   js  6.03  -6.99 -28.71  11.82   4.71   5.00   ch  ...   \n",
       "\n",
       "       var21  var22  var23  var24  var25  var26  var27 var28  var29  var30  \n",
       "0       8.94 -12.76     ub  12.06   2.46   4.73  -1.72  0.91     ev   8.00  \n",
       "1      31.02  34.76     cz   1.44   9.44  13.56  -2.24  0.24     ev  -2.90  \n",
       "2      23.26   9.50     ri   7.77   8.70  -1.75   5.96  1.91     ev  22.67  \n",
       "3      29.25  -1.53     ri   8.94  19.33  23.73   5.54  0.85     ev  36.31  \n",
       "4       2.19  10.24     ub   8.92   5.48  -0.28   4.01  1.21     ev  11.33  \n",
       "...      ...    ...    ...    ...    ...    ...    ...   ...    ...    ...  \n",
       "29995  25.00  18.14     tf   8.54  14.95  32.69  -3.71  1.20     ev  -7.12  \n",
       "29996  26.49  22.88     qu  12.11  11.45  11.56   3.52  0.92     ev  13.28  \n",
       "29997  39.61   4.40     ub   7.75   1.65  17.83   9.67 -0.64     ev  31.07  \n",
       "29998  44.22   0.46     tf  11.50   5.90  20.33   4.17  0.78     ev  40.53  \n",
       "29999  -0.06  25.11     yv   7.67   6.34  20.05   7.85  1.20     ev   4.74  \n",
       "\n",
       "[30000 rows x 31 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convertir la columna \"payment\" a numérica considerando \"Success\" como 1 y cualquier otra cosa como 0\n",
    "pdl[\"payment\"] = np.where(pdl[\"payment\"] == \"Success\",1,0)\n",
    "pdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['payment', 'var1', 'var2', 'var3', 'var4', 'var5', 'var6', 'var7',\n",
      "       'var8', 'var9', 'var10', 'var11', 'var12', 'var13', 'var14', 'var15',\n",
      "       'var16', 'var17', 'var18', 'var19', 'var20', 'var21', 'var22', 'var23',\n",
      "       'var24', 'var25', 'var26', 'var27', 'var28', 'var29', 'var30'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "columnas = pdl.columns\n",
    "print(columnas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>payment</th>\n",
       "      <th>var3</th>\n",
       "      <th>var4</th>\n",
       "      <th>var5</th>\n",
       "      <th>var6</th>\n",
       "      <th>var7</th>\n",
       "      <th>var8</th>\n",
       "      <th>var12</th>\n",
       "      <th>var14</th>\n",
       "      <th>var15</th>\n",
       "      <th>...</th>\n",
       "      <th>var23_da</th>\n",
       "      <th>var23_fe</th>\n",
       "      <th>var23_po</th>\n",
       "      <th>var23_qu</th>\n",
       "      <th>var23_ri</th>\n",
       "      <th>var23_sy</th>\n",
       "      <th>var23_tf</th>\n",
       "      <th>var23_ub</th>\n",
       "      <th>var23_yv</th>\n",
       "      <th>var29_ev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3.11</td>\n",
       "      <td>16.06</td>\n",
       "      <td>-4.60</td>\n",
       "      <td>22.34</td>\n",
       "      <td>13.53</td>\n",
       "      <td>1.53</td>\n",
       "      <td>4.46</td>\n",
       "      <td>4.93</td>\n",
       "      <td>26.48</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3.35</td>\n",
       "      <td>11.18</td>\n",
       "      <td>-18.55</td>\n",
       "      <td>6.68</td>\n",
       "      <td>12.78</td>\n",
       "      <td>6.62</td>\n",
       "      <td>4.04</td>\n",
       "      <td>-0.76</td>\n",
       "      <td>16.21</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>4.15</td>\n",
       "      <td>29.19</td>\n",
       "      <td>18.91</td>\n",
       "      <td>16.40</td>\n",
       "      <td>3.67</td>\n",
       "      <td>5.72</td>\n",
       "      <td>-4.41</td>\n",
       "      <td>1.21</td>\n",
       "      <td>29.06</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6.23</td>\n",
       "      <td>15.70</td>\n",
       "      <td>2.81</td>\n",
       "      <td>4.46</td>\n",
       "      <td>5.13</td>\n",
       "      <td>8.66</td>\n",
       "      <td>2.14</td>\n",
       "      <td>3.56</td>\n",
       "      <td>23.61</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.28</td>\n",
       "      <td>20.71</td>\n",
       "      <td>14.98</td>\n",
       "      <td>11.19</td>\n",
       "      <td>17.66</td>\n",
       "      <td>1.13</td>\n",
       "      <td>14.93</td>\n",
       "      <td>2.20</td>\n",
       "      <td>-19.16</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>1</td>\n",
       "      <td>3.85</td>\n",
       "      <td>12.75</td>\n",
       "      <td>47.62</td>\n",
       "      <td>3.34</td>\n",
       "      <td>17.22</td>\n",
       "      <td>7.00</td>\n",
       "      <td>17.62</td>\n",
       "      <td>0.57</td>\n",
       "      <td>41.55</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>0</td>\n",
       "      <td>3.32</td>\n",
       "      <td>25.31</td>\n",
       "      <td>15.90</td>\n",
       "      <td>10.96</td>\n",
       "      <td>10.13</td>\n",
       "      <td>10.32</td>\n",
       "      <td>13.03</td>\n",
       "      <td>4.40</td>\n",
       "      <td>49.51</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>0</td>\n",
       "      <td>2.98</td>\n",
       "      <td>19.28</td>\n",
       "      <td>16.20</td>\n",
       "      <td>-1.70</td>\n",
       "      <td>9.45</td>\n",
       "      <td>-8.44</td>\n",
       "      <td>2.60</td>\n",
       "      <td>-0.67</td>\n",
       "      <td>20.66</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>16.41</td>\n",
       "      <td>22.80</td>\n",
       "      <td>-9.99</td>\n",
       "      <td>26.89</td>\n",
       "      <td>-1.10</td>\n",
       "      <td>6.07</td>\n",
       "      <td>4.13</td>\n",
       "      <td>49.06</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>1</td>\n",
       "      <td>6.03</td>\n",
       "      <td>-6.99</td>\n",
       "      <td>-28.71</td>\n",
       "      <td>11.82</td>\n",
       "      <td>4.71</td>\n",
       "      <td>5.00</td>\n",
       "      <td>15.76</td>\n",
       "      <td>2.58</td>\n",
       "      <td>31.30</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       payment  var3   var4   var5   var6   var7   var8  var12  var14  var15  \\\n",
       "0            1  3.11  16.06  -4.60  22.34  13.53   1.53   4.46   4.93  26.48   \n",
       "1            0  3.35  11.18 -18.55   6.68  12.78   6.62   4.04  -0.76  16.21   \n",
       "2            0  4.15  29.19  18.91  16.40   3.67   5.72  -4.41   1.21  29.06   \n",
       "3            1  6.23  15.70   2.81   4.46   5.13   8.66   2.14   3.56  23.61   \n",
       "4            1  1.28  20.71  14.98  11.19  17.66   1.13  14.93   2.20 -19.16   \n",
       "...        ...   ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "29995        1  3.85  12.75  47.62   3.34  17.22   7.00  17.62   0.57  41.55   \n",
       "29996        0  3.32  25.31  15.90  10.96  10.13  10.32  13.03   4.40  49.51   \n",
       "29997        0  2.98  19.28  16.20  -1.70   9.45  -8.44   2.60  -0.67  20.66   \n",
       "29998        1 -0.30  16.41  22.80  -9.99  26.89  -1.10   6.07   4.13  49.06   \n",
       "29999        1  6.03  -6.99 -28.71  11.82   4.71   5.00  15.76   2.58  31.30   \n",
       "\n",
       "       ...  var23_da  var23_fe  var23_po  var23_qu  var23_ri  var23_sy  \\\n",
       "0      ...     False     False     False     False     False     False   \n",
       "1      ...     False     False     False     False     False     False   \n",
       "2      ...     False     False     False     False      True     False   \n",
       "3      ...     False     False     False     False      True     False   \n",
       "4      ...     False     False     False     False     False     False   \n",
       "...    ...       ...       ...       ...       ...       ...       ...   \n",
       "29995  ...     False     False     False     False     False     False   \n",
       "29996  ...     False     False     False      True     False     False   \n",
       "29997  ...     False     False     False     False     False     False   \n",
       "29998  ...     False     False     False     False     False     False   \n",
       "29999  ...     False     False     False     False     False     False   \n",
       "\n",
       "       var23_tf  var23_ub  var23_yv  var29_ev  \n",
       "0         False      True     False      True  \n",
       "1         False     False     False      True  \n",
       "2         False     False     False      True  \n",
       "3         False     False     False      True  \n",
       "4         False      True     False      True  \n",
       "...         ...       ...       ...       ...  \n",
       "29995      True     False     False      True  \n",
       "29996     False     False     False      True  \n",
       "29997     False      True     False      True  \n",
       "29998      True     False     False      True  \n",
       "29999     False     False      True      True  \n",
       "\n",
       "[30000 rows x 63 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in columnas:\n",
    "    # Si la columna es de tipo objeto la descartamos\n",
    "    if pdl[col].dtype == 'object':\n",
    "        # Creamos columnas dummy para cada valor único de la columna tipp 'object'\n",
    "        temp = pd.get_dummies(pdl[col], drop_first = True, prefix=col)\n",
    "        pdl = pd.concat([pdl, temp], axis=1)\n",
    "        pdl.drop(col, axis=1, inplace=True)\n",
    "\n",
    "pdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>payment</th>\n",
       "      <th>var3</th>\n",
       "      <th>var4</th>\n",
       "      <th>var5</th>\n",
       "      <th>var6</th>\n",
       "      <th>var7</th>\n",
       "      <th>var8</th>\n",
       "      <th>var12</th>\n",
       "      <th>var14</th>\n",
       "      <th>var15</th>\n",
       "      <th>...</th>\n",
       "      <th>var23_da</th>\n",
       "      <th>var23_fe</th>\n",
       "      <th>var23_po</th>\n",
       "      <th>var23_qu</th>\n",
       "      <th>var23_ri</th>\n",
       "      <th>var23_sy</th>\n",
       "      <th>var23_tf</th>\n",
       "      <th>var23_ub</th>\n",
       "      <th>var23_yv</th>\n",
       "      <th>var29_ev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3.11</td>\n",
       "      <td>16.06</td>\n",
       "      <td>-4.60</td>\n",
       "      <td>22.34</td>\n",
       "      <td>13.53</td>\n",
       "      <td>1.53</td>\n",
       "      <td>4.46</td>\n",
       "      <td>4.93</td>\n",
       "      <td>26.48</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3.35</td>\n",
       "      <td>11.18</td>\n",
       "      <td>-18.55</td>\n",
       "      <td>6.68</td>\n",
       "      <td>12.78</td>\n",
       "      <td>6.62</td>\n",
       "      <td>4.04</td>\n",
       "      <td>-0.76</td>\n",
       "      <td>16.21</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>4.15</td>\n",
       "      <td>29.19</td>\n",
       "      <td>18.91</td>\n",
       "      <td>16.40</td>\n",
       "      <td>3.67</td>\n",
       "      <td>5.72</td>\n",
       "      <td>-4.41</td>\n",
       "      <td>1.21</td>\n",
       "      <td>29.06</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6.23</td>\n",
       "      <td>15.70</td>\n",
       "      <td>2.81</td>\n",
       "      <td>4.46</td>\n",
       "      <td>5.13</td>\n",
       "      <td>8.66</td>\n",
       "      <td>2.14</td>\n",
       "      <td>3.56</td>\n",
       "      <td>23.61</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.28</td>\n",
       "      <td>20.71</td>\n",
       "      <td>14.98</td>\n",
       "      <td>11.19</td>\n",
       "      <td>17.66</td>\n",
       "      <td>1.13</td>\n",
       "      <td>14.93</td>\n",
       "      <td>2.20</td>\n",
       "      <td>-19.16</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>1</td>\n",
       "      <td>3.85</td>\n",
       "      <td>12.75</td>\n",
       "      <td>47.62</td>\n",
       "      <td>3.34</td>\n",
       "      <td>17.22</td>\n",
       "      <td>7.00</td>\n",
       "      <td>17.62</td>\n",
       "      <td>0.57</td>\n",
       "      <td>41.55</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>0</td>\n",
       "      <td>3.32</td>\n",
       "      <td>25.31</td>\n",
       "      <td>15.90</td>\n",
       "      <td>10.96</td>\n",
       "      <td>10.13</td>\n",
       "      <td>10.32</td>\n",
       "      <td>13.03</td>\n",
       "      <td>4.40</td>\n",
       "      <td>49.51</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>0</td>\n",
       "      <td>2.98</td>\n",
       "      <td>19.28</td>\n",
       "      <td>16.20</td>\n",
       "      <td>-1.70</td>\n",
       "      <td>9.45</td>\n",
       "      <td>-8.44</td>\n",
       "      <td>2.60</td>\n",
       "      <td>-0.67</td>\n",
       "      <td>20.66</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>16.41</td>\n",
       "      <td>22.80</td>\n",
       "      <td>-9.99</td>\n",
       "      <td>26.89</td>\n",
       "      <td>-1.10</td>\n",
       "      <td>6.07</td>\n",
       "      <td>4.13</td>\n",
       "      <td>49.06</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>1</td>\n",
       "      <td>6.03</td>\n",
       "      <td>-6.99</td>\n",
       "      <td>-28.71</td>\n",
       "      <td>11.82</td>\n",
       "      <td>4.71</td>\n",
       "      <td>5.00</td>\n",
       "      <td>15.76</td>\n",
       "      <td>2.58</td>\n",
       "      <td>31.30</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       payment  var3   var4   var5   var6   var7   var8  var12  var14  var15  \\\n",
       "0            1  3.11  16.06  -4.60  22.34  13.53   1.53   4.46   4.93  26.48   \n",
       "1            0  3.35  11.18 -18.55   6.68  12.78   6.62   4.04  -0.76  16.21   \n",
       "2            0  4.15  29.19  18.91  16.40   3.67   5.72  -4.41   1.21  29.06   \n",
       "3            1  6.23  15.70   2.81   4.46   5.13   8.66   2.14   3.56  23.61   \n",
       "4            1  1.28  20.71  14.98  11.19  17.66   1.13  14.93   2.20 -19.16   \n",
       "...        ...   ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "29995        1  3.85  12.75  47.62   3.34  17.22   7.00  17.62   0.57  41.55   \n",
       "29996        0  3.32  25.31  15.90  10.96  10.13  10.32  13.03   4.40  49.51   \n",
       "29997        0  2.98  19.28  16.20  -1.70   9.45  -8.44   2.60  -0.67  20.66   \n",
       "29998        1 -0.30  16.41  22.80  -9.99  26.89  -1.10   6.07   4.13  49.06   \n",
       "29999        1  6.03  -6.99 -28.71  11.82   4.71   5.00  15.76   2.58  31.30   \n",
       "\n",
       "       ...  var23_da  var23_fe  var23_po  var23_qu  var23_ri  var23_sy  \\\n",
       "0      ...     False     False     False     False     False     False   \n",
       "1      ...     False     False     False     False     False     False   \n",
       "2      ...     False     False     False     False      True     False   \n",
       "3      ...     False     False     False     False      True     False   \n",
       "4      ...     False     False     False     False     False     False   \n",
       "...    ...       ...       ...       ...       ...       ...       ...   \n",
       "29995  ...     False     False     False     False     False     False   \n",
       "29996  ...     False     False     False      True     False     False   \n",
       "29997  ...     False     False     False     False     False     False   \n",
       "29998  ...     False     False     False     False     False     False   \n",
       "29999  ...     False     False     False     False     False     False   \n",
       "\n",
       "       var23_tf  var23_ub  var23_yv  var29_ev  \n",
       "0         False      True     False      True  \n",
       "1         False     False     False      True  \n",
       "2         False     False     False      True  \n",
       "3         False     False     False      True  \n",
       "4         False      True     False      True  \n",
       "...         ...       ...       ...       ...  \n",
       "29995      True     False     False      True  \n",
       "29996     False     False     False      True  \n",
       "29997     False      True     False      True  \n",
       "29998      True     False     False      True  \n",
       "29999     False     False      True      True  \n",
       "\n",
       "[30000 rows x 63 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdl.dropna(axis=0,inplace=True)\n",
    "pdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['payment', 'var3', 'var4', 'var5', 'var6', 'var7', 'var8', 'var12',\n",
       "       'var14', 'var15', 'var16', 'var18', 'var20', 'var21', 'var22', 'var24',\n",
       "       'var25', 'var26', 'var27', 'var28', 'var30', 'var1_ma', 'var1_qw',\n",
       "       'var1_wv', 'var2_hk', 'var2_js', 'var2_lo', 'var2_py', 'var2_qf',\n",
       "       'var2_rv', 'var2_xn', 'var2_zg', 'var9_ja', 'var9_nv', 'var10_ld',\n",
       "       'var10_pe', 'var11_te', 'var13_iz', 'var13_kh', 'var13_np', 'var13_pf',\n",
       "       'var13_te', 'var13_xm', 'var17_bw', 'var17_ki', 'var17_ov', 'var17_zk',\n",
       "       'var19_ev', 'var19_fh', 'var19_hw', 'var19_me', 'var19_qu', 'var19_tg',\n",
       "       'var23_da', 'var23_fe', 'var23_po', 'var23_qu', 'var23_ri', 'var23_sy',\n",
       "       'var23_tf', 'var23_ub', 'var23_yv', 'var29_ev'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdl.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdl_train, pdl_test = train_test_split(pdl, test_size = 0.2, random_state = 2)\n",
    "\n",
    "#x_train=pdl_train.drop([\"payment\"],1)\n",
    "x_train = pdl_train.drop(columns=\"payment\")\n",
    "y_train = pdl_train[\"payment\"]\n",
    "\n",
    "#x_test=pdl_test.drop([\"payment\"],1)\n",
    "x_test=pdl_test.drop(columns=\"payment\")\n",
    "y_test=pdl_test[\"payment\"]\n",
    "\n",
    "# Reiniciamos los índices de los dataframes tras el split\n",
    "x_train.reset_index(drop=True,inplace=True)\n",
    "y_train.reset_index(drop=True,inplace=True)\n",
    "# Yo agregué también el reset_index a los test\n",
    "x_test.reset_index(drop=True,inplace=True)\n",
    "y_test.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var3</th>\n",
       "      <th>var4</th>\n",
       "      <th>var5</th>\n",
       "      <th>var6</th>\n",
       "      <th>var7</th>\n",
       "      <th>var8</th>\n",
       "      <th>var12</th>\n",
       "      <th>var14</th>\n",
       "      <th>var15</th>\n",
       "      <th>var16</th>\n",
       "      <th>...</th>\n",
       "      <th>var23_da</th>\n",
       "      <th>var23_fe</th>\n",
       "      <th>var23_po</th>\n",
       "      <th>var23_qu</th>\n",
       "      <th>var23_ri</th>\n",
       "      <th>var23_sy</th>\n",
       "      <th>var23_tf</th>\n",
       "      <th>var23_ub</th>\n",
       "      <th>var23_yv</th>\n",
       "      <th>var29_ev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.02</td>\n",
       "      <td>22.08</td>\n",
       "      <td>8.69</td>\n",
       "      <td>-9.24</td>\n",
       "      <td>21.06</td>\n",
       "      <td>2.21</td>\n",
       "      <td>1.33</td>\n",
       "      <td>2.00</td>\n",
       "      <td>7.62</td>\n",
       "      <td>-5.77</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.09</td>\n",
       "      <td>11.25</td>\n",
       "      <td>23.46</td>\n",
       "      <td>12.11</td>\n",
       "      <td>29.57</td>\n",
       "      <td>4.77</td>\n",
       "      <td>8.86</td>\n",
       "      <td>2.38</td>\n",
       "      <td>29.48</td>\n",
       "      <td>28.14</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.77</td>\n",
       "      <td>25.95</td>\n",
       "      <td>3.95</td>\n",
       "      <td>17.74</td>\n",
       "      <td>19.78</td>\n",
       "      <td>9.02</td>\n",
       "      <td>3.76</td>\n",
       "      <td>0.72</td>\n",
       "      <td>34.00</td>\n",
       "      <td>17.19</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.75</td>\n",
       "      <td>12.47</td>\n",
       "      <td>-4.54</td>\n",
       "      <td>-1.42</td>\n",
       "      <td>-10.32</td>\n",
       "      <td>9.11</td>\n",
       "      <td>8.37</td>\n",
       "      <td>7.91</td>\n",
       "      <td>4.86</td>\n",
       "      <td>3.67</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.47</td>\n",
       "      <td>7.90</td>\n",
       "      <td>31.60</td>\n",
       "      <td>2.53</td>\n",
       "      <td>-12.66</td>\n",
       "      <td>3.64</td>\n",
       "      <td>1.87</td>\n",
       "      <td>5.07</td>\n",
       "      <td>19.04</td>\n",
       "      <td>28.70</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23995</th>\n",
       "      <td>-1.28</td>\n",
       "      <td>9.09</td>\n",
       "      <td>11.89</td>\n",
       "      <td>5.58</td>\n",
       "      <td>17.29</td>\n",
       "      <td>15.65</td>\n",
       "      <td>8.28</td>\n",
       "      <td>0.77</td>\n",
       "      <td>23.06</td>\n",
       "      <td>9.79</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23996</th>\n",
       "      <td>1.60</td>\n",
       "      <td>9.52</td>\n",
       "      <td>14.64</td>\n",
       "      <td>6.11</td>\n",
       "      <td>20.14</td>\n",
       "      <td>17.93</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.14</td>\n",
       "      <td>8.22</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23997</th>\n",
       "      <td>0.54</td>\n",
       "      <td>22.37</td>\n",
       "      <td>42.39</td>\n",
       "      <td>12.41</td>\n",
       "      <td>3.54</td>\n",
       "      <td>5.09</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.45</td>\n",
       "      <td>24.50</td>\n",
       "      <td>4.45</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23998</th>\n",
       "      <td>3.37</td>\n",
       "      <td>11.72</td>\n",
       "      <td>17.49</td>\n",
       "      <td>-2.63</td>\n",
       "      <td>0.83</td>\n",
       "      <td>12.47</td>\n",
       "      <td>17.58</td>\n",
       "      <td>0.32</td>\n",
       "      <td>3.22</td>\n",
       "      <td>11.61</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23999</th>\n",
       "      <td>5.21</td>\n",
       "      <td>28.45</td>\n",
       "      <td>27.84</td>\n",
       "      <td>14.82</td>\n",
       "      <td>2.13</td>\n",
       "      <td>0.82</td>\n",
       "      <td>-0.73</td>\n",
       "      <td>2.27</td>\n",
       "      <td>-4.48</td>\n",
       "      <td>-18.34</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24000 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       var3   var4   var5   var6   var7   var8  var12  var14  var15  var16  \\\n",
       "0      1.02  22.08   8.69  -9.24  21.06   2.21   1.33   2.00   7.62  -5.77   \n",
       "1      2.09  11.25  23.46  12.11  29.57   4.77   8.86   2.38  29.48  28.14   \n",
       "2      6.77  25.95   3.95  17.74  19.78   9.02   3.76   0.72  34.00  17.19   \n",
       "3      2.75  12.47  -4.54  -1.42 -10.32   9.11   8.37   7.91   4.86   3.67   \n",
       "4      4.47   7.90  31.60   2.53 -12.66   3.64   1.87   5.07  19.04  28.70   \n",
       "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "23995 -1.28   9.09  11.89   5.58  17.29  15.65   8.28   0.77  23.06   9.79   \n",
       "23996  1.60   9.52  14.64   6.11  20.14  17.93   0.50   1.19   1.14   8.22   \n",
       "23997  0.54  22.37  42.39  12.41   3.54   5.09   0.22   1.45  24.50   4.45   \n",
       "23998  3.37  11.72  17.49  -2.63   0.83  12.47  17.58   0.32   3.22  11.61   \n",
       "23999  5.21  28.45  27.84  14.82   2.13   0.82  -0.73   2.27  -4.48 -18.34   \n",
       "\n",
       "       ...  var23_da  var23_fe  var23_po  var23_qu  var23_ri  var23_sy  \\\n",
       "0      ...     False      True     False     False     False     False   \n",
       "1      ...     False     False     False     False     False     False   \n",
       "2      ...     False     False     False     False     False     False   \n",
       "3      ...     False     False     False     False     False     False   \n",
       "4      ...     False     False     False     False     False     False   \n",
       "...    ...       ...       ...       ...       ...       ...       ...   \n",
       "23995  ...     False     False     False     False     False     False   \n",
       "23996  ...     False     False     False     False     False     False   \n",
       "23997  ...     False      True     False     False     False     False   \n",
       "23998  ...     False     False     False     False     False      True   \n",
       "23999  ...     False     False     False     False     False     False   \n",
       "\n",
       "       var23_tf  var23_ub  var23_yv  var29_ev  \n",
       "0         False     False     False     False  \n",
       "1          True     False     False     False  \n",
       "2         False      True     False      True  \n",
       "3         False      True     False      True  \n",
       "4          True     False     False      True  \n",
       "...         ...       ...       ...       ...  \n",
       "23995     False      True     False      True  \n",
       "23996      True     False     False      True  \n",
       "23997     False     False     False      True  \n",
       "23998     False     False     False      True  \n",
       "23999      True     False     False      True  \n",
       "\n",
       "[24000 rows x 62 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        1\n",
       "2        0\n",
       "3        0\n",
       "4        1\n",
       "        ..\n",
       "23995    0\n",
       "23996    1\n",
       "23997    0\n",
       "23998    0\n",
       "23999    1\n",
       "Name: payment, Length: 24000, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var3</th>\n",
       "      <th>var4</th>\n",
       "      <th>var5</th>\n",
       "      <th>var6</th>\n",
       "      <th>var7</th>\n",
       "      <th>var8</th>\n",
       "      <th>var12</th>\n",
       "      <th>var14</th>\n",
       "      <th>var15</th>\n",
       "      <th>var16</th>\n",
       "      <th>...</th>\n",
       "      <th>var23_da</th>\n",
       "      <th>var23_fe</th>\n",
       "      <th>var23_po</th>\n",
       "      <th>var23_qu</th>\n",
       "      <th>var23_ri</th>\n",
       "      <th>var23_sy</th>\n",
       "      <th>var23_tf</th>\n",
       "      <th>var23_ub</th>\n",
       "      <th>var23_yv</th>\n",
       "      <th>var29_ev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.21</td>\n",
       "      <td>32.16</td>\n",
       "      <td>43.85</td>\n",
       "      <td>9.91</td>\n",
       "      <td>13.86</td>\n",
       "      <td>-8.21</td>\n",
       "      <td>5.20</td>\n",
       "      <td>7.29</td>\n",
       "      <td>30.36</td>\n",
       "      <td>5.08</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.51</td>\n",
       "      <td>5.64</td>\n",
       "      <td>37.51</td>\n",
       "      <td>15.29</td>\n",
       "      <td>12.90</td>\n",
       "      <td>16.09</td>\n",
       "      <td>12.35</td>\n",
       "      <td>3.19</td>\n",
       "      <td>-10.04</td>\n",
       "      <td>30.15</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.54</td>\n",
       "      <td>31.75</td>\n",
       "      <td>-7.42</td>\n",
       "      <td>2.94</td>\n",
       "      <td>-7.38</td>\n",
       "      <td>3.09</td>\n",
       "      <td>4.12</td>\n",
       "      <td>1.91</td>\n",
       "      <td>1.92</td>\n",
       "      <td>-0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.10</td>\n",
       "      <td>3.26</td>\n",
       "      <td>7.83</td>\n",
       "      <td>10.62</td>\n",
       "      <td>12.58</td>\n",
       "      <td>2.64</td>\n",
       "      <td>8.39</td>\n",
       "      <td>2.68</td>\n",
       "      <td>26.09</td>\n",
       "      <td>11.85</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.01</td>\n",
       "      <td>0.69</td>\n",
       "      <td>33.50</td>\n",
       "      <td>18.47</td>\n",
       "      <td>1.32</td>\n",
       "      <td>-3.04</td>\n",
       "      <td>13.46</td>\n",
       "      <td>4.95</td>\n",
       "      <td>27.50</td>\n",
       "      <td>9.31</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5995</th>\n",
       "      <td>1.07</td>\n",
       "      <td>-21.82</td>\n",
       "      <td>43.81</td>\n",
       "      <td>9.87</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.82</td>\n",
       "      <td>5.93</td>\n",
       "      <td>0.32</td>\n",
       "      <td>36.79</td>\n",
       "      <td>6.83</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>7.59</td>\n",
       "      <td>5.30</td>\n",
       "      <td>-5.69</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.57</td>\n",
       "      <td>8.76</td>\n",
       "      <td>24.87</td>\n",
       "      <td>2.92</td>\n",
       "      <td>13.97</td>\n",
       "      <td>15.94</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997</th>\n",
       "      <td>6.84</td>\n",
       "      <td>25.04</td>\n",
       "      <td>42.00</td>\n",
       "      <td>12.25</td>\n",
       "      <td>14.17</td>\n",
       "      <td>3.70</td>\n",
       "      <td>14.03</td>\n",
       "      <td>4.85</td>\n",
       "      <td>4.04</td>\n",
       "      <td>27.27</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5998</th>\n",
       "      <td>0.13</td>\n",
       "      <td>21.81</td>\n",
       "      <td>31.68</td>\n",
       "      <td>-1.19</td>\n",
       "      <td>15.32</td>\n",
       "      <td>14.15</td>\n",
       "      <td>1.23</td>\n",
       "      <td>2.66</td>\n",
       "      <td>33.42</td>\n",
       "      <td>6.49</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999</th>\n",
       "      <td>4.21</td>\n",
       "      <td>4.96</td>\n",
       "      <td>20.19</td>\n",
       "      <td>8.77</td>\n",
       "      <td>2.66</td>\n",
       "      <td>6.83</td>\n",
       "      <td>20.19</td>\n",
       "      <td>1.48</td>\n",
       "      <td>11.04</td>\n",
       "      <td>22.59</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      var3   var4   var5   var6   var7   var8  var12  var14  var15  var16  \\\n",
       "0     4.21  32.16  43.85   9.91  13.86  -8.21   5.20   7.29  30.36   5.08   \n",
       "1     0.51   5.64  37.51  15.29  12.90  16.09  12.35   3.19 -10.04  30.15   \n",
       "2     2.54  31.75  -7.42   2.94  -7.38   3.09   4.12   1.91   1.92  -0.63   \n",
       "3     6.10   3.26   7.83  10.62  12.58   2.64   8.39   2.68  26.09  11.85   \n",
       "4     5.01   0.69  33.50  18.47   1.32  -3.04  13.46   4.95  27.50   9.31   \n",
       "...    ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "5995  1.07 -21.82  43.81   9.87   1.03   1.82   5.93   0.32  36.79   6.83   \n",
       "5996  7.59   5.30  -5.69   1.28   4.57   8.76  24.87   2.92  13.97  15.94   \n",
       "5997  6.84  25.04  42.00  12.25  14.17   3.70  14.03   4.85   4.04  27.27   \n",
       "5998  0.13  21.81  31.68  -1.19  15.32  14.15   1.23   2.66  33.42   6.49   \n",
       "5999  4.21   4.96  20.19   8.77   2.66   6.83  20.19   1.48  11.04  22.59   \n",
       "\n",
       "      ...  var23_da  var23_fe  var23_po  var23_qu  var23_ri  var23_sy  \\\n",
       "0     ...     False     False     False     False      True     False   \n",
       "1     ...     False     False     False     False     False     False   \n",
       "2     ...     False     False     False     False     False     False   \n",
       "3     ...     False     False     False     False     False     False   \n",
       "4     ...     False     False     False     False     False     False   \n",
       "...   ...       ...       ...       ...       ...       ...       ...   \n",
       "5995  ...     False     False     False     False     False     False   \n",
       "5996  ...     False      True     False     False     False     False   \n",
       "5997  ...     False     False     False     False      True     False   \n",
       "5998  ...     False     False     False     False     False     False   \n",
       "5999  ...     False      True     False     False     False     False   \n",
       "\n",
       "      var23_tf  var23_ub  var23_yv  var29_ev  \n",
       "0        False     False     False      True  \n",
       "1        False      True     False      True  \n",
       "2         True     False     False      True  \n",
       "3        False      True     False     False  \n",
       "4         True     False     False      True  \n",
       "...        ...       ...       ...       ...  \n",
       "5995      True     False     False      True  \n",
       "5996     False     False     False      True  \n",
       "5997     False     False     False      True  \n",
       "5998      True     False     False      True  \n",
       "5999     False     False     False      True  \n",
       "\n",
       "[6000 rows x 62 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "5995    1\n",
       "5996    1\n",
       "5997    0\n",
       "5998    1\n",
       "5999    0\n",
       "Name: payment, Length: 6000, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pregunta 1:\n",
    "Construye un  clasificador usando K-NN con 3 vecinos y otro usando un árbol de decisión. ¿Cuál produce mejor resultado?. ¿Qué métrica has usado?. Según el árbol de decisión, ¿qué métricas son las más relevantes?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.77      0.74      3762\n",
      "           1       0.56      0.49      0.52      2238\n",
      "\n",
      "    accuracy                           0.67      6000\n",
      "   macro avg       0.64      0.63      0.63      6000\n",
      "weighted avg       0.66      0.67      0.66      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Implementamos el clasificador KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 3).fit(x_train, y_train)\n",
    "y_pred = knn.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      3762\n",
      "           1       0.70      0.72      0.71      2238\n",
      "\n",
      "    accuracy                           0.78      6000\n",
      "   macro avg       0.77      0.77      0.77      6000\n",
      "weighted avg       0.78      0.78      0.78      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Implementamos el clasificador de Decission Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "dt = DecisionTreeClassifier().fit(x_train, y_train)\n",
    "y_pred = dt.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.89453816e-02, 1.44237594e-02, 1.95369121e-02, 1.89470078e-02,\n",
       "       5.16948241e-02, 1.85134729e-02, 1.73327637e-02, 1.83339485e-02,\n",
       "       1.95593770e-02, 7.75759181e-02, 1.73669732e-02, 1.64429222e-02,\n",
       "       1.84418180e-02, 2.20436500e-02, 2.12014470e-02, 3.60153612e-01,\n",
       "       1.79498733e-02, 1.96754912e-02, 1.55815796e-02, 1.66161557e-02,\n",
       "       9.90860065e-04, 1.41197203e-03, 1.53350214e-03, 2.01641948e-03,\n",
       "       3.39095757e-04, 1.58080027e-04, 2.00276240e-03, 1.36714013e-03,\n",
       "       9.46475646e-04, 1.71154345e-03, 8.97872406e-04, 1.01186342e-03,\n",
       "       2.05817610e-03, 2.20770902e-03, 9.20984803e-04, 1.38893149e-03,\n",
       "       1.98081954e-03, 6.95743226e-04, 8.87108234e-04, 1.24870800e-03,\n",
       "       2.14105938e-03, 5.08351110e-04, 8.94185854e-02, 1.51874356e-03,\n",
       "       1.42361299e-03, 9.00460924e-04, 1.72463520e-03, 1.07544120e-03,\n",
       "       8.69082803e-05, 1.33181078e-03, 1.04893737e-03, 1.71458960e-03,\n",
       "       4.59841260e-04, 6.68525789e-04, 4.02265084e-04, 8.82610486e-04,\n",
       "       6.55815896e-04, 8.90152835e-04, 1.31627744e-03, 4.68981016e-02,\n",
       "       4.27339703e-03, 1.45472215e-02])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtenemos las métricas más importantes según el clasificador de Decision Tree\n",
    "importances = dt.feature_importances_\n",
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Obtenemos las métricas más importantes según el clasificador de Decision Tree\n",
    "importances = dt.feature_importances_\n",
    "# Obtenemos los nombres de las 5 variables más importantes\n",
    "indices = np.argsort(importances)[::-1][:5]\n",
    "\n",
    "# Generamos un gráfico de barras con las 5 variables más importantes\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=importances[indices], y=x_train.columns[indices])\n",
    "plt.title(\"Importancia de las variables\")\n",
    "plt.xlabel(\"Importancia\")\n",
    "plt.ylabel(\"Variables\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pregunta 2:\n",
    "Repite el ejercicio anterior usando normalización de los datos y compara los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos el normalizador MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Normalizamos los datos de entrenamiento\n",
    "scaler = MinMaxScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "# Normalizamos los datos de test\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.39443255, 0.54583195, 0.39434965, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.44025696, 0.45591166, 0.48565776, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.64068522, 0.57796413, 0.36504698, ..., 1.        , 0.        ,\n",
       "        1.        ],\n",
       "       ...,\n",
       "       [0.3738758 , 0.54823979, 0.60268299, ..., 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       [0.49507495, 0.45981402, 0.44875124, ..., 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       [0.5738758 , 0.59872136, 0.51273492, ..., 0.        , 0.        ,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.53104925, 0.62952507, 0.6117087 , ..., 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       [0.37259101, 0.40933245, 0.57251484, ..., 1.        , 0.        ,\n",
       "        1.        ],\n",
       "       [0.45952891, 0.62612089, 0.29475767, ..., 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       ...,\n",
       "       [0.64368308, 0.5704085 , 0.60027201, ..., 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       [0.35631692, 0.54359017, 0.53647379, ..., 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       [0.53104925, 0.40368648, 0.46544263, ..., 0.        , 0.        ,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.72      0.70      3762\n",
      "           1       0.48      0.44      0.46      2238\n",
      "\n",
      "    accuracy                           0.62      6000\n",
      "   macro avg       0.58      0.58      0.58      6000\n",
      "weighted avg       0.61      0.62      0.61      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Implementamos el clasificador KNN para los datos normalizados\n",
    "knn = KNeighborsClassifier(n_neighbors = 3).fit(x_train_scaled, y_train)\n",
    "y_pred = knn.predict(x_test_scaled)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      3762\n",
      "           1       0.70      0.72      0.71      2238\n",
      "\n",
      "    accuracy                           0.78      6000\n",
      "   macro avg       0.77      0.77      0.77      6000\n",
      "weighted avg       0.78      0.78      0.78      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Implementamos el clasificador Decission Tree para los datos normalizados\n",
    "dt = DecisionTreeClassifier().fit(x_train_scaled, y_train)\n",
    "y_pred = dt.predict(x_test_scaled)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pregunta 3:\n",
    "Usando GridSearchCV, identifica para un clasificador K-NN el numero de vecinos entre 1 y 30 que optimiza el resultado usando como scoring la precision y con 10 folds para la validacion cruzada. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m grid \u001b[38;5;241m=\u001b[39m GridSearchCV(knn, param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Ajustamos el modelo\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[43mgrid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Obtenemos los mejores parámetros\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMejores parámetros: \u001b[39m\u001b[38;5;124m\"\u001b[39m, grid\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[0;32m~/anaconda3/envs/dataScience/lib/python3.9/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/dataScience/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1024\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1018\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1019\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1020\u001b[0m     )\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1024\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1027\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1028\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/dataScience/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1571\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1570\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1571\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/dataScience/lib/python3.9/site-packages/sklearn/model_selection/_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    963\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    964\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    965\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    966\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    967\u001b[0m         )\n\u001b[1;32m    968\u001b[0m     )\n\u001b[0;32m--> 970\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    989\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    990\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    993\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/dataScience/lib/python3.9/site-packages/sklearn/utils/parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     76\u001b[0m )\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/dataScience/lib/python3.9/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/anaconda3/envs/dataScience/lib/python3.9/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/anaconda3/envs/dataScience/lib/python3.9/site-packages/sklearn/utils/parallel.py:139\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/dataScience/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:888\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    885\u001b[0m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_error\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    887\u001b[0m fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[0;32m--> 888\u001b[0m test_scores \u001b[38;5;241m=\u001b[39m \u001b[43m_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscore_params_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    891\u001b[0m score_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time \u001b[38;5;241m-\u001b[39m fit_time\n\u001b[1;32m    892\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_train_score:\n",
      "File \u001b[0;32m~/anaconda3/envs/dataScience/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:949\u001b[0m, in \u001b[0;36m_score\u001b[0;34m(estimator, X_test, y_test, scorer, score_params, error_score)\u001b[0m\n\u001b[1;32m    947\u001b[0m         scores \u001b[38;5;241m=\u001b[39m scorer(estimator, X_test, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mscore_params)\n\u001b[1;32m    948\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 949\u001b[0m         scores \u001b[38;5;241m=\u001b[39m \u001b[43mscorer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mscore_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    950\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    951\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(scorer, _MultimetricScorer):\n\u001b[1;32m    952\u001b[0m         \u001b[38;5;66;03m# If `_MultimetricScorer` raises exception, the `error_score`\u001b[39;00m\n\u001b[1;32m    953\u001b[0m         \u001b[38;5;66;03m# parameter is equal to \"raise\".\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/dataScience/lib/python3.9/site-packages/sklearn/metrics/_scorer.py:288\u001b[0m, in \u001b[0;36m_BaseScorer.__call__\u001b[0;34m(self, estimator, X, y_true, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    286\u001b[0m     _kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m sample_weight\n\u001b[0;32m--> 288\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_cached_call\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/dataScience/lib/python3.9/site-packages/sklearn/metrics/_scorer.py:380\u001b[0m, in \u001b[0;36m_Scorer._score\u001b[0;34m(self, method_caller, estimator, X, y_true, **kwargs)\u001b[0m\n\u001b[1;32m    378\u001b[0m pos_label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m is_regressor(estimator) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_pos_label()\n\u001b[1;32m    379\u001b[0m response_method \u001b[38;5;241m=\u001b[39m _check_response_method(estimator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_method)\n\u001b[0;32m--> 380\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmethod_caller\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_get_response_method_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_method\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    387\u001b[0m scoring_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sign \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_score_func(y_true, y_pred, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mscoring_kwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/dataScience/lib/python3.9/site-packages/sklearn/metrics/_scorer.py:90\u001b[0m, in \u001b[0;36m_cached_call\u001b[0;34m(cache, estimator, response_method, *args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m response_method \u001b[38;5;129;01min\u001b[39;00m cache:\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cache[response_method]\n\u001b[0;32m---> 90\u001b[0m result, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_get_response_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     95\u001b[0m     cache[response_method] \u001b[38;5;241m=\u001b[39m result\n",
      "File \u001b[0;32m~/anaconda3/envs/dataScience/lib/python3.9/site-packages/sklearn/utils/_response.py:214\u001b[0m, in \u001b[0;36m_get_response_values\u001b[0;34m(estimator, X, response_method, pos_label, return_response_method_used)\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m pos_label \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m target_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    212\u001b[0m         pos_label \u001b[38;5;241m=\u001b[39m classes[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 214\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mprediction_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prediction_method\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict_proba\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict_log_proba\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    217\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m _process_predict_proba(\n\u001b[1;32m    218\u001b[0m         y_pred\u001b[38;5;241m=\u001b[39my_pred,\n\u001b[1;32m    219\u001b[0m         target_type\u001b[38;5;241m=\u001b[39mtarget_type,\n\u001b[1;32m    220\u001b[0m         classes\u001b[38;5;241m=\u001b[39mclasses,\n\u001b[1;32m    221\u001b[0m         pos_label\u001b[38;5;241m=\u001b[39mpos_label,\n\u001b[1;32m    222\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/dataScience/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:262\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrute\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m ArgKminClassMode\u001b[38;5;241m.\u001b[39mis_usable_for(\n\u001b[1;32m    260\u001b[0m         X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric\n\u001b[1;32m    261\u001b[0m     ):\n\u001b[0;32m--> 262\u001b[0m         probabilities \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputs_2d_:\n\u001b[1;32m    264\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mstack(\n\u001b[1;32m    265\u001b[0m                 [\n\u001b[1;32m    266\u001b[0m                     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_[idx][np\u001b[38;5;241m.\u001b[39margmax(probas, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    269\u001b[0m                 axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    270\u001b[0m             )\n",
      "File \u001b[0;32m~/anaconda3/envs/dataScience/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:371\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m probabilities\n\u001b[1;32m    369\u001b[0m     \u001b[38;5;66;03m# In that case, we do not need the distances to perform\u001b[39;00m\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;66;03m# the weighting so we do not compute them.\u001b[39;00m\n\u001b[0;32m--> 371\u001b[0m     neigh_ind \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m     neigh_dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/dataScience/lib/python3.9/site-packages/sklearn/neighbors/_base.py:869\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    862\u001b[0m use_pairwise_distances_reductions \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrute\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    864\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m ArgKmin\u001b[38;5;241m.\u001b[39mis_usable_for(\n\u001b[1;32m    865\u001b[0m         X \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meffective_metric_\n\u001b[1;32m    866\u001b[0m     )\n\u001b[1;32m    867\u001b[0m )\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_pairwise_distances_reductions:\n\u001b[0;32m--> 869\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mArgKmin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m        \u001b[49m\u001b[43mY\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_X\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m        \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_neighbors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meffective_metric_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetric_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meffective_metric_params_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_distance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrute\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecomputed\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m issparse(X)\n\u001b[1;32m    881\u001b[0m ):\n\u001b[1;32m    882\u001b[0m     results \u001b[38;5;241m=\u001b[39m _kneighbors_from_graph(\n\u001b[1;32m    883\u001b[0m         X, n_neighbors\u001b[38;5;241m=\u001b[39mn_neighbors, return_distance\u001b[38;5;241m=\u001b[39mreturn_distance\n\u001b[1;32m    884\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/dataScience/lib/python3.9/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py:281\u001b[0m, in \u001b[0;36mArgKmin.compute\u001b[0;34m(cls, X, Y, k, metric, chunk_size, metric_kwargs, strategy, return_distance)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute the argkmin reduction.\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \n\u001b[1;32m    202\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;124;03mreturns.\u001b[39;00m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m Y\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat64:\n\u001b[0;32m--> 281\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mArgKmin64\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mY\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m        \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetric_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_distance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m Y\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat32:\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ArgKmin32\u001b[38;5;241m.\u001b[39mcompute(\n\u001b[1;32m    294\u001b[0m         X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m    295\u001b[0m         Y\u001b[38;5;241m=\u001b[39mY,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    301\u001b[0m         return_distance\u001b[38;5;241m=\u001b[39mreturn_distance,\n\u001b[1;32m    302\u001b[0m     )\n",
      "File \u001b[0;32msklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx:59\u001b[0m, in \u001b[0;36msklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/dataScience/lib/python3.9/site-packages/threadpoolctl.py:592\u001b[0m, in \u001b[0;36m_ThreadpoolLimiter.__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    590\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m--> 592\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mtype\u001b[39m, value, traceback):\n\u001b[1;32m    593\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrestore_original_limits()\n\u001b[1;32m    595\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap\u001b[39m(\u001b[38;5;28mcls\u001b[39m, controller, \u001b[38;5;241m*\u001b[39m, limits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, user_api\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Importamos la función de GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Definimos los parámetros a ajustar\n",
    "param_grid = {'n_neighbors': list(range(1, 31))}\n",
    "\n",
    "# Creamos el clasificador KNN\n",
    "knn = KNeighborsClassifier()\n",
    "# Creamos el objeto GridSearchCV\n",
    "grid = GridSearchCV(knn, param_grid, cv=10, scoring='accuracy')\n",
    "# Ajustamos el modelo\n",
    "grid.fit(x_train_scaled, y_train)\n",
    "# Obtenemos los mejores parámetros\n",
    "print(\"Mejores parámetros: \", grid.best_params_)\n",
    "# Obtenemos el mejor modelo\n",
    "best_knn = grid.best_estimator_\n",
    "# Predecimos con el mejor modelo\n",
    "y_pred = best_knn.predict(x_test_scaled)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pregunta 4:\n",
    "Obten la matriz de confusion del clasificador optimo anterior. ¿como lees cada uno de los valores?¿que valor de precission y recall tiene el clasificador optimizado con precission?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pregunta 5:\n",
    "Construye ahora una red neuronal usando MLPClassifier de dos capas. Prueba diferente numero de neuronas por capa. ¿afecta al resultado?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 6:\n",
    "GradientBoostingClasifier es uno de los metodos de scikitlearn que mejor resultados suelen producir. Implementa un clasificador utilizando GradientBoostingClasifier considerando 0.05, 0.1, 0.15, 0.2, 0.25, 0.3 como learning rate.¿que learning rate produce un resultado optimo usando recall?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 6:\n",
    "Usando la matriz de confusion de los tres casos (GradientBoosting, MLP y K-NN) y derivando las metricas que te parezcan oportunas ¿Que clasificador de los 3 seleccionarias y porque?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataScience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
